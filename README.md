# ITER-Diffusion

## Description

This repository builds upon the [ITER](https://arxiv.org/abs/1909.10707) framework, originally proposed in the paper:

> *Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning*

The core idea of ITER is to use data augmentation strategies to improve the sample efficiency of Deep Reinforcement Learning (RL) agents by leveraging transformations that preserve task invariance.

**ITER-Diffusion** extends this approach by exploring how diffusion models can be used within RL frameworks for data augmentation, with the goal of further improving sample efficiency.

---

### Original Repository

For detailed information about the original ITER implementation, please refer to the [birlrobotics/iter_ker_ger](https://github.com/birlrobotics/iter_ker_ger) repository. For setup instructions, you may also consult that repository, as the process here is nearly identical.

---

## What's New in `ITER-Diffusion`?

- **Diffusion Model-Based Data Augmentation:**  
  Incorporates a diffusion model to synthesize high-quality augmented experience trajectories for RL agents.
- **Sample Efficiency:**  
  Investigates improved sample efficiency in RL tasks by leveraging synthetic transitions generated by the diffusion model.
- **Plug-and-Play with Existing ITER Pipelines:**  
  The codebase is designed to be compatible with existing ITER/Hindsight Experience Replay setups, enabling easy integration.
- **Comprehensive Evaluation:**  
  Provides structure for evaluating the impact of diffusion-based augmentation and logs ddpm metrics.
- **Modular & Extensible:**  
  The architecture allows others to experiment with different diffusion models and augmentation strategies.

---
```bash
python -m baselines.run --alg=her --env=FetchPickAndPlace-v1 --num_timesteps=1e6 --n_cycles=100 --save_path=/home/user/policies/her/iter --log_path=/home/user/log_data/her/iter --before_GER_minibatch_size=256 --n_KER=8 --n_GER=4 --ddpm_time_steps=50 --ddpm_tol=0.05 --ddpm_train_start=100 --ddpm_aug_start=150 --ddpm_aug_freq=20
```
---

## Setup

### 1. Clone the Repository

```bash
git clone https://github.com/EzgiAskin/ITER-Diffusion.git
cd ITER-Diffusion
```

### 2. Create and Activate Environment

It is recommended to use [conda](https://docs.conda.io/).

```bash
conda create -n iter-diffusion python=3.7
conda activate iter-diffusion
```

### 3. Install MuJoCo and Other Dependencies
todo
If you plan to run experiments using MuJoCo or other robotics environments

```bash
pip install torch
```

## References

- ITER:  
  "Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning."* [arXiv:1909.10707](https://arxiv.org/abs/1909.10707)
- DDPM:  
  "Denoising Diffusion Probabilistic Models."* [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)

## IMPORTANT NOTICE
This repository is not final and will be updated soon
---
